{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7aa246b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model, Sequential\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Input\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_excel('Raw_Data_v0.xlsx', engine='openpyxl')\n",
    "df = df.drop(columns=[\n",
    "    'Ref#', 'Heat treatment', 'Other RM/Rivet/part cost (€/Part)',\n",
    "    'Gross Weight (g)', 'Other assembled RM/Rivet/part',\n",
    "])\n",
    "\n",
    "num_cols = [\n",
    "    'Annual target quantity', 'Raw Material Cost (€/kg)', 'Thickness (mm)',\n",
    "    'Part Net Weight (g)', 'Surface Treatment cost (€/Part)',\n",
    "    'Final Raw Material cost (€/Part)', 'Heat Treatment cost (€/Part)'\n",
    "]\n",
    "cat_cols = [\n",
    "    'Production', 'Raw Material Designation',\n",
    "    'Surface Treatment', 'Raw Material'\n",
    "]\n",
    "\n",
    "df[num_cols] = df[num_cols].fillna(0)\n",
    "df[cat_cols] = df[cat_cols].fillna('Missing')\n",
    "TARGET = 'Total cost with amortization (€/part)'\n",
    "\n",
    "# Apply square root transformations\n",
    "for col in num_cols + [TARGET]:\n",
    "    df[col] = np.sqrt(df[col])\n",
    "\n",
    "X = df[num_cols + cat_cols]\n",
    "y = df[TARGET]\n",
    "cat_indices = [X.columns.get_loc(col) for col in cat_cols]\n",
    "\n",
    "# Best parameters with MAPE tracking\n",
    "best_params = {\n",
    "    'iterations': 786,\n",
    "    'learning_rate': 0.0317,\n",
    "    'depth': 5,\n",
    "    'l2_leaf_reg': 2.216,\n",
    "    'border_count': 83,\n",
    "    'min_data_in_leaf': 34,\n",
    "    'random_strength': 1.742,\n",
    "    'subsample': 0.940,\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'feature_border_type': 'MaxLogSum',\n",
    "    'grow_policy': 'SymmetricTree',\n",
    "    'monotone_constraints': [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "    'eval_metric': 'MAPE',\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "cost_components = [\n",
    "    'Surface Treatment cost (€/Part)',\n",
    "    'Final Raw Material cost (€/Part)',\n",
    "    'Heat Treatment cost (€/Part)'\n",
    "]\n",
    "\n",
    "# 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "metrics = {\n",
    "    'MAE': [], 'RMSE': [], 'MAPE': [], 'R2': [],\n",
    "    'violations_before': [], 'violations_after': [],\n",
    "    'within_10%': [], 'MoE_Improvement': []\n",
    "}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # 1. Data Encoding for Autoencoder\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    cat_train = ohe.fit_transform(X_train[cat_cols])\n",
    "    cat_test = ohe.transform(X_test[cat_cols])\n",
    "    \n",
    "    encoded_train = np.hstack([X_train[num_cols].values, cat_train])\n",
    "    encoded_test = np.hstack([X_test[num_cols].values, cat_test])\n",
    "    \n",
    "    # 2. Latent Space Construction\n",
    "    input_dim = encoded_train.shape[1]\n",
    "    latent_dim = max(4, min(8, input_dim//2))\n",
    "    \n",
    "    # Autoencoder architecture\n",
    "    autoencoder = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(latent_dim, activation='relu', name='latent'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(input_dim, activation='linear')\n",
    "    ])\n",
    "    autoencoder.compile(optimizer=Adam(0.001), loss='mse')\n",
    "    autoencoder.fit(encoded_train, encoded_train, \n",
    "                   epochs=50, batch_size=32, verbose=0)\n",
    "    \n",
    "    # 3. Expert Clustering in Latent Space\n",
    "    latent_model = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('latent').output)\n",
    "    latent_train = latent_model.predict(encoded_train)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=3, init='k-means++', n_init=20, random_state=42)\n",
    "    train_clusters = kmeans.fit_predict(latent_train)\n",
    "    \n",
    "    # 4. Expert Model Training\n",
    "    experts = []\n",
    "    for cluster in range(3):\n",
    "        mask = (train_clusters == cluster)\n",
    "        if np.sum(mask) < 10:  # Skip small clusters\n",
    "            continue\n",
    "            \n",
    "        # Use modified parameters for experts\n",
    "        expert_params = best_params.copy()\n",
    "        expert_params['iterations'] = max(100, best_params['iterations']//2)\n",
    "        \n",
    "        expert = CatBoostRegressor(**expert_params, cat_features=cat_indices)\n",
    "        expert.fit(X_train[mask], y_train[mask])\n",
    "        experts.append((expert, cluster))\n",
    "    \n",
    "    # 5. Baseline Model for Comparison\n",
    "    baseline_model = CatBoostRegressor(**best_params, cat_features=cat_indices)\n",
    "    baseline_model.fit(X_train, y_train)\n",
    "    baseline_pred = baseline_model.predict(X_test)\n",
    "    \n",
    "    # 6. MoE Prediction\n",
    "    test_latent = latent_model.predict(encoded_test)\n",
    "    test_clusters = kmeans.predict(test_latent)\n",
    "    \n",
    "    y_pred = np.zeros_like(y_test)\n",
    "    for expert, cluster in experts:\n",
    "        mask = (test_clusters == cluster)\n",
    "        if mask.any():\n",
    "            y_pred[mask] = expert.predict(X_test[mask])\n",
    "    \n",
    "    # Handle unclustered samples with baseline\n",
    "    unclustered_mask = ~np.isin(test_clusters, [c for _, c in experts])\n",
    "    if np.any(unclustered_mask):\n",
    "        y_pred[unclustered_mask] = baseline_model.predict(X_test[unclustered_mask])\n",
    "    \n",
    "    # 7. Evaluation\n",
    "    y_pred_orig = np.square(y_pred)\n",
    "    y_test_orig = np.square(y_test)\n",
    "    baseline_pred_orig = np.square(baseline_pred)\n",
    "    \n",
    "    # Calculate component costs sum\n",
    "    sum_costs = np.sum(np.square(X_test[cost_components]), axis=1)\n",
    "    \n",
    "    # Track violations\n",
    "    violations_before = np.sum(y_pred_orig < sum_costs)\n",
    "    y_pred_clipped = np.maximum(y_pred_orig, sum_costs)\n",
    "    violations_after = np.sum(y_pred_clipped < sum_costs)\n",
    "    \n",
    "    # Store metrics\n",
    "    metrics['MAE'].append(mean_absolute_error(y_test_orig, y_pred_clipped))\n",
    "    metrics['RMSE'].append(np.sqrt(mean_squared_error(y_test_orig, y_pred_clipped)))\n",
    "    metrics['MAPE'].append(np.mean(np.abs((y_test_orig - y_pred_clipped)/y_test_orig)) * 100)\n",
    "    metrics['R2'].append(r2_score(y_test_orig, y_pred_clipped))\n",
    "    metrics['violations_before'].append(violations_before)\n",
    "    metrics['violations_after'].append(violations_after)\n",
    "    metrics['within_10%'].append(np.sum(np.abs((y_pred_clipped - y_test_orig)/y_test_orig) <= 0.1))\n",
    "    metrics['MoE_Improvement'].append(r2_score(y_test_orig, y_pred_clipped) - r2_score(y_test_orig, baseline_pred_orig))\n",
    "    \n",
    "    # Cluster analysis\n",
    "    print(f\"\\n=== Fold {fold+1} Cluster Analysis ===\")\n",
    "    for cluster in range(3):\n",
    "        if cluster in [c for _, c in experts]:\n",
    "            cluster_data = X_train[train_clusters == cluster]\n",
    "            print(f\"Cluster {cluster} (n={len(cluster_data)})\")\n",
    "            print(cluster_data[cost_components].mean().sort_values(ascending=False))\n",
    "    \n",
    "    # Plot learning curve for last fold\n",
    "    if fold == 9:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # MoE vs Baseline comparison\n",
    "        plt.scatter(y_test_orig, y_pred_clipped, alpha=0.5, label='MoE Predictions')\n",
    "        plt.scatter(y_test_orig, baseline_pred_orig, alpha=0.5, label='Baseline Predictions')\n",
    "        plt.plot([y_test_orig.min(), y_test_orig.max()], \n",
    "                [y_test_orig.min(), y_test_orig.max()], 'k--')\n",
    "        plt.title('Prediction Comparison: MoE vs Baseline')\n",
    "        plt.xlabel('True Values')\n",
    "        plt.ylabel('Predictions')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Final results\n",
    "print(\"\\n=== Final Validation Results ===\")\n",
    "print(f\"MAE: {np.mean(metrics['MAE']):.2f} ± {np.std(metrics['MAE']):.2f}\")\n",
    "print(f\"RMSE: {np.mean(metrics['RMSE']):.2f} ± {np.std(metrics['RMSE']):.2f}\")\n",
    "print(f\"MAPE: {np.mean(metrics['MAPE']):.2f}% ± {np.std(metrics['MAPE']):.2f}\")\n",
    "print(f\"R²: {np.mean(metrics['R2']):.2f} ± {np.std(metrics['R2']):.2f}\")\n",
    "print(f\"MoE R² Improvement: {np.mean(metrics['MoE_Improvement']):.3f} ± {np.std(metrics['MoE_Improvement']):.3f}\")\n",
    "print(f\"Violations before clipping: {sum(metrics['violations_before'])} ({sum(metrics['violations_before'])/len(X)*100:.2f}%)\")\n",
    "print(f\"Violations after clipping: {sum(metrics['violations_after'])} ({sum(metrics['violations_after'])/len(X)*100:.2f}%)\")\n",
    "print(f\"Predictions within ±10%: {sum(metrics['within_10%'])/len(X)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3c8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
